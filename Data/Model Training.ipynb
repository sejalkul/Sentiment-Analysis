{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3182916",
   "metadata": {},
   "source": [
    "<h1>Election Compaign - Sentimental analysis</h1>\n",
    "<br>\n",
    "<strong>Election campaign sentiment analysis involves analyzing public sentiment towards political candidates, parties, or issues during an election campaign. This analysis typically involves processing large volumes of textual data from various sources such as social media, news articles, blogs, and public forums to gauge the overall sentiment towards specific entities or topics related to the election.</strong>\n",
    "<br>\n",
    "<h3>1. Import Libraries</h3>\n",
    "<ol>\n",
    "  <li><strong>pandas</strong>: A powerful data manipulation library in Python, used for data analysis and manipulation. It provides data structures like DataFrame and tools for reading and writing data between various formats.</li>\n",
    "  <li><strong>numpy</strong>: A fundamental package for scientific computing with Python. It provides support for multi-dimensional arrays and matrices, along with mathematical functions to operate on these arrays.</li>\n",
    "  <li><strong>matplotlib.pyplot</strong>: A plotting library for creating static, interactive, and animated visualizations in Python. It is widely used for generating plots, histograms, bar charts, scatterplots, etc.</li>\n",
    "  <li><strong>seaborn</strong>: A data visualization library based on matplotlib, providing a high-level interface for drawing attractive and informative statistical graphics.</li>\n",
    "  <li><strong>re</strong>: The built-in regular expression module in Python, used for pattern matching and string manipulation tasks.</li>\n",
    "  <li><strong>nltk</strong>: The Natural Language Toolkit is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for tokenization, stemming, tagging, parsing, and classification.</li>\n",
    "  <li><strong>sklearn.model_selection.train_test_split</strong>: A function from scikit-learn used to split arrays or matrices into random train and test subsets.</li>\n",
    "  <li><strong>sklearn.feature_extraction.text.TfidfVectorizer</strong>: A scikit-learn class used to convert a collection of raw documents into a matrix of TF-IDF features.</li>\n",
    "  <li><strong>sklearn.pipeline.Pipeline</strong>: A scikit-learn class used to sequentially apply a list of transforms and a final estimator. Pipelines help to automate workflows and apply transformations consistently.</li>\n",
    "  <li><strong>sklearn.metrics</strong>: A module in scikit-learn containing various evaluation metrics such as accuracy_score, confusion_matrix, classification_report, etc., used to evaluate the performance of machine learning models.</li>\n",
    "  <li><strong>sklearn.naive_bayes</strong>: The scikit-learn module containing implementations of Naive Bayes classifiers, which are a family of simple probabilistic classifiers based on Bayes' theorem with strong independence assumptions between the features.</li>\n",
    "  <li><strong>sklearn.linear_model.LogisticRegression</strong>: The scikit-learn class for logistic regression, a linear model used for binary classification tasks.</li>\n",
    "  <li><strong>sklearn.svm.LinearSVC</strong>: The scikit-learn class for linear support vector classification, a linear model used for binary and multiclass classification tasks.</li>\n",
    "  <li><strong>sklearn.neighbors.KNeighborsClassifier</strong>: The scikit-learn class for K-nearest neighbors classification, a non-parametric method used for classification and regression tasks.</li>\n",
    "  <li><strong>bs4.BeautifulSoup</strong>: A Python library for pulling data out of HTML and XML files. It provides functions and methods for parsing HTML and XML documents, extracting information, and navigating the parse tree.</li>\n",
    "  <li><strong>nltk.corpus.stopwords</strong>: A list of common stopwords (e.g., \"the\", \"and\", \"is\") in English, provided by the NLTK library.</li>\n",
    "  <li><strong>sklearn.ensemble.RandomForestClassifier</strong>: The scikit-learn class for random forest classification, an ensemble learning method that operates by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.</li>\n",
    "  <li><strong>sklearn.ensemble.GradientBoostingClassifier</strong>: The scikit-learn class for gradient boosting classification, an ensemble learning method that builds a strong model by sequentially adding weak models (typically decision trees) and correcting errors made by the previous models.</li>\n",
    "</ol>\n",
    "These libraries and modules are essential for tasks such as data preprocessing, feature extraction, model training, evaluation, and visualization in machine learning and natural language processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec13995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,ConfusionMatrixDisplay\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc7752a",
   "metadata": {},
   "source": [
    "<h3>2. Read the dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6c8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training_data.csv\", nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc0b02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ndtv anchor let go over to aap live press conf...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sambit patra attacks rahul gandhi over his cow...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>crediting the bjp with taking development to s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet sentiment\n",
       "0           0  ndtv anchor let go over to aap live press conf...  negative\n",
       "1           1  sambit patra attacks rahul gandhi over his cow...   neutral\n",
       "2           2  crediting the bjp with taking development to s...   neutral"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1652755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  10000 non-null  int64 \n",
      " 1   tweet       10000 non-null  object\n",
      " 2   sentiment   10000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892fabf7",
   "metadata": {},
   "source": [
    "<h3>Data Pre Processing</h3>\n",
    "<ol>\n",
    "  <li><strong><code>removeHTML(raw_text)</code></strong>: This function takes a raw text input and uses the <code>BeautifulSoup</code> library to remove any HTML elements present in the text. It returns the clean text without HTML tags.</li>\n",
    "  <li><strong><code>removeSpecialChar(raw_text)</code></strong>: This function takes a raw text input and uses regular expressions to remove any special characters and numbers from the text. It only retains alphabetic characters (both uppercase and lowercase). The cleaned text is then returned.</li>\n",
    "  <li><strong><code>toLowerCase(raw_text)</code></strong>: This function takes a raw text input and converts all characters to lowercase. It then splits the text into individual words and joins them back together with spaces. This ensures that all text is in lowercase format.</li>\n",
    "  <li><strong><code>removeStopWords(raw_text)</code></strong>: This function takes a raw text input and removes common English stopwords using NLTK's <code>stopwords</code> corpus. Stopwords are words that occur frequently in the language but do not carry significant meaning (e.g., \"the\", \"is\", \"and\"). The function returns the text with stopwords removed.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb4686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove html elements from the reviews\n",
    "def removeHTML(raw_text):\n",
    "    clean_HTML = BeautifulSoup(raw_text, 'lxml').get_text() \n",
    "    return clean_HTML\n",
    "\n",
    "# function to remove special characters and numbers from the reviews4961\n",
    "def removeSpecialChar(raw_text):\n",
    "    clean_SpecialChar = re.sub(\"[^a-zA-Z]\", \" \", raw_text)  \n",
    "    return clean_SpecialChar\n",
    "\n",
    "# function to convert all reviews into lower case\n",
    "def toLowerCase(raw_text):\n",
    "    clean_LowerCase = raw_text.lower().split()\n",
    "    return( \" \".join(clean_LowerCase)) \n",
    "\n",
    "# function to remove stop words from the reviews\n",
    "def removeStopWords(raw_text):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    words = [w for w in raw_text if not w in stops]\n",
    "    return( \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d1699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and Test Data Split\n",
    "\n",
    "X = data['tweet']\n",
    "Y = data['sentiment']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4f71b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_training clean set\n",
    "X_train_cleaned = []\n",
    "\n",
    "for val in X_train:\n",
    "    val = removeHTML(val)\n",
    "    val = removeSpecialChar(val)\n",
    "    val = toLowerCase(val)\n",
    "    X_train_cleaned.append(val) \n",
    "    \n",
    "# X_testing clean set\n",
    "X_test_cleaned = []\n",
    "\n",
    "for val in X_test:\n",
    "    val = removeHTML(val)\n",
    "    val = removeSpecialChar(val)\n",
    "    val = toLowerCase(val)\n",
    "    X_test_cleaned.append(val) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc343127",
   "metadata": {},
   "source": [
    "<h3>4. Training the model</h3>\n",
    "<ol>\n",
    "  <li><strong><code>tvec = TfidfVectorizer(use_idf=True, strip_accents='ascii')</code></strong>: This line initializes a TF-IDF vectorizer object named <code>tvec</code>. TF-IDF (Term Frequency-Inverse Document Frequency) is a numerical statistic that reflects the importance of a word in a document relative to a collection of documents. The <code>use_idf=True</code> parameter indicates that the vectorizer should include IDF (Inverse Document Frequency) in its computation, which helps to downweight terms that appear frequently across all documents. The <code>strip_accents='ascii'</code> parameter specifies that accents and diacritics should be stripped from the text during tokenization, ensuring that all characters are in ASCII format.</li>\n",
    "  <li><strong><code>X_train_tvec = tvec.fit_transform(X_train_cleaned)</code></strong>: This line fits the TF-IDF vectorizer to the training data (<code>X_train_cleaned</code>) and transforms it into a TF-IDF matrix <code>X_train_tvec</code>. The <code>fit_transform</code> method both fits the vectorizer to the training data and transforms the data into a matrix in a single step. Each row of the matrix represents a document from the training data, and each column represents a unique term in the corpus. The values in the matrix are the TF-IDF scores for each term in each document. This TF-IDF matrix is commonly used as input for machine learning algorithms in natural language processing tasks such as text classification, clustering, and information retrieval.</li>\n",
    "</ol>\n",
    "\n",
    "Once the data vectorized it has fed into the machine learners for training purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975908d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(use_idf=True,\n",
    "strip_accents='ascii')\n",
    "\n",
    "X_train_tvec = tvec.fit_transform(X_train_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a66988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "negative           0.92    0.44      0.59   686.00\n",
      "neutral            0.68    0.94      0.79  1198.00\n",
      "positive           0.83    0.75      0.79  1116.00\n",
      "accuracy           0.76    0.76      0.76     0.76\n",
      "macro avg          0.81    0.71      0.72  3000.00\n",
      "weighted avg       0.79    0.76      0.75  3000.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Support Vector Classifier model\n",
    "svr_lin = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svr_lin.fit(X_train_tvec, Y_train)\n",
    "\n",
    "svr_lin_predictions = svr_lin.predict(tvec.transform(X_test_cleaned))\n",
    "report = classification_report(Y_test,svr_lin_predictions, output_dict=True)\n",
    "data_report = pd.DataFrame(report).transpose().round(2)\n",
    "print(data_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "443c6fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "negative           0.47    0.41      0.44   686.00\n",
      "neutral            0.51    0.69      0.58  1198.00\n",
      "positive           0.59    0.41      0.48  1116.00\n",
      "accuracy           0.52    0.52      0.52     0.52\n",
      "macro avg          0.52    0.50      0.50  3000.00\n",
      "weighted avg       0.53    0.52      0.51  3000.00\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbor model\n",
    "knn = KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "knn.fit(X_train_tvec, Y_train)\n",
    "\n",
    "# Predict using training and testing data and display the accuracy, f-1 score, precision for Positive and Negative Sentiment Classifiers \n",
    "knn_predictions = knn.predict(tvec.transform(X_test_cleaned))\n",
    "report = classification_report(Y_test,knn_predictions, output_dict=True)\n",
    "data_report = pd.DataFrame(report).transpose().round(2)\n",
    "print(data_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b8ae706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "negative           0.92    0.56      0.70   686.00\n",
      "neutral            0.72    0.99      0.83  1198.00\n",
      "positive           0.92    0.76      0.83  1116.00\n",
      "accuracy           0.81    0.81      0.81     0.81\n",
      "macro avg          0.85    0.77      0.79  3000.00\n",
      "weighted avg       0.84    0.81      0.80  3000.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Gradient Boosting model\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train_tvec, Y_train)\n",
    "\n",
    "# Predict using training and testing data and display the accuracy, f-1 score, precision for Positive and Negative Sentiment Classifiers \n",
    "gb_predictions = gb.predict(tvec.transform(X_test_cleaned))\n",
    "report = classification_report(Y_test, gb_predictions, output_dict=True)\n",
    "data_report = pd.DataFrame(report).transpose().round(2)\n",
    "print(data_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e602b03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "negative           0.74    0.60      0.66   686.00\n",
      "neutral            0.75    0.79      0.77  1198.00\n",
      "positive           0.75    0.79      0.77  1116.00\n",
      "accuracy           0.75    0.75      0.75     0.75\n",
      "macro avg          0.75    0.73      0.73  3000.00\n",
      "weighted avg       0.75    0.75      0.74  3000.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Artificial Neural Network Model\n",
    "ann = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000)  # You can adjust the hidden_layer_sizes and max_iter as needed\n",
    "ann.fit(X_train_tvec, Y_train)\n",
    "\n",
    "# Predict using training and testing data and display the evaluation metrics\n",
    "ann_predictions = ann.predict(tvec.transform(X_test_cleaned))\n",
    "report = classification_report(Y_test, ann_predictions, output_dict=True)\n",
    "data_report = pd.DataFrame(report).transpose().round(2)\n",
    "print(data_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde90e9d",
   "metadata": {},
   "source": [
    "<ol>\n",
    "  <li><strong>Import Statements:</strong> The code imports necessary libraries and modules, including time, warnings, and specific classifiers and ensemble methods from scikit-learn.</li>\n",
    "  <li><strong>Suppress FutureWarning:</strong> This line suppresses the FutureWarning related to the dual parameter of SVM (Support Vector Machine) classifiers, ensuring that it does not clutter the output during execution.</li>\n",
    "  <li><strong>Initialize Base Classifiers:</strong> Four base classifiers are initialized with default parameters: LinearSVC (Linear Support Vector Classifier), KNeighborsClassifier (K-Nearest Neighbors Classifier), MLPClassifier (Multi-layer Perceptron Classifier), and GradientBoostingClassifier (Gradient Boosting Classifier).</li>\n",
    "  <li><strong>Initialize Stacked Classifier:</strong> The StackingClassifier is initialized with the previously defined base classifiers. It uses a RandomForestClassifier as the final estimator and performs 2-fold cross-validation (<code>cv=2</code>).</li>\n",
    "  <li><strong>Training the Stacked Classifier:</strong> The StackingClassifier is trained on the training data (<code>X_train_tvec</code> and <code>Y_train</code>).</li>\n",
    "  <li><strong>Make Predictions:</strong> The trained StackingClassifier is used to make predictions on the testing data (<code>X_test_cleaned</code>).</li>\n",
    "  <li><strong>Classification Report:</strong> The classification report is generated using scikit-learn's <code>classification_report</code> function, providing insights into the precision, recall, F1-score, and support for each class.</li>\n",
    "  <li><strong>Confusion Matrix:</strong> A confusion matrix is generated using scikit-learn's <code>confusion_matrix</code> function and visualized using seaborn's heatmap, showing the true and predicted class labels.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f4c8b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Stacked Classifier...\n",
      "Stacked Classifier Initialized.\n",
      "Training Stacked Classifier...\n",
      "Stacked Classifier Training Complete.\n",
      "Making Predictions...\n",
      "Prediction Complete.\n",
      "              precision  recall  f1-score  support\n",
      "negative           0.88    0.78      0.83   686.00\n",
      "neutral            0.85    0.96      0.90  1198.00\n",
      "positive           0.92    0.85      0.89  1116.00\n",
      "accuracy           0.88    0.88      0.88     0.88\n",
      "macro avg          0.88    0.87      0.87  3000.00\n",
      "weighted avg       0.88    0.88      0.88  3000.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Axes.set of <Axes: >>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Suppress FutureWarning for SVM dual parameter\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Initialize base classifiers with default parameters\n",
    "base_classifiers = [\n",
    "    ('linear_svc', LinearSVC()),\n",
    "    ('kneighbors', KNeighborsClassifier()),\n",
    "    ('mlp', MLPClassifier(max_iter=100)),\n",
    "    ('gradient_boosting', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "# Initialize the stacked classifier\n",
    "stacked_classifier = StackingClassifier(\n",
    "    estimators=base_classifiers,\n",
    "    final_estimator=RandomForestClassifier(n_estimators=100),  \n",
    "    cv=2\n",
    ")\n",
    "\n",
    "print(\"Initializing Stacked Classifier...\")\n",
    "time.sleep(1)  # Simulating initialization time\n",
    "print(\"Stacked Classifier Initialized.\")\n",
    "\n",
    "# Train the stacked classifier\n",
    "print(\"Training Stacked Classifier...\")\n",
    "stacked_classifier.fit(X_train_tvec, Y_train)\n",
    "print(\"Stacked Classifier Training Complete.\")\n",
    "\n",
    "# Predict using testing data\n",
    "print(\"Making Predictions...\")\n",
    "stacked_predictions = stacked_classifier.predict(tvec.transform(X_test_cleaned))\n",
    "print(\"Prediction Complete.\")\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(Y_test, stacked_predictions, output_dict=True)\n",
    "data_report = pd.DataFrame(report).transpose().round(2)\n",
    "print(data_report)\n",
    "\n",
    "# Confusion matrix\n",
    "ax = plt.subplot()\n",
    "cm = confusion_matrix(Y_test, stacked_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='RdPu')\n",
    "ax.set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04578910",
   "metadata": {},
   "source": [
    "<ul>\n",
    "  <li>\n",
    "    <strong>Initialization of Stacked Classifier:</strong>\n",
    "    <ul>\n",
    "      <li>\n",
    "        <strong>Initialization of Base Classifiers:</strong>\n",
    "        <ul>\n",
    "          <li>Import necessary modules for StackingClassifier and weak learners: LinearSVC, KNeighborsClassifier, MLPClassifier, and GradientBoostingClassifier.</li>\n",
    "          <li>Define a list called <code>base_classifiers</code> containing tuples of the form <code>(name, model)</code>, where <code>name</code> is a string identifier for the base classifier, and <code>model</code> is an instance of the corresponding classifier.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>\n",
    "        <strong>Initialization of Stacked Classifier:</strong>\n",
    "        <ul>\n",
    "          <li>Initialize a StackingClassifier object named <code>stacked_classifier</code>.</li>\n",
    "          <li>Specify parameters such as <code>estimators</code>, <code>final_estimator</code>, and <code>cv</code>.</li>\n",
    "          <li><code>estimators</code> is set to <code>base_classifiers</code>, which contains the list of base classifiers.</li>\n",
    "          <li><code>final_estimator=RandomForestClassifier(n_estimators=100)</code> specifies the final estimator, which is a RandomForestClassifier with 100 estimators.</li>\n",
    "          <li><code>cv=2</code> indicates the number of cross-validation folds to use during training.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>\n",
    "        <strong>Simulated Initialization Time:</strong>\n",
    "        <ul>\n",
    "          <li>Use <code>time.sleep(1)</code> to simulate initialization time, delaying the program's execution by 1 second.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>\n",
    "        <strong>Training Stacked Classifier:</strong>\n",
    "        <ul>\n",
    "          <li>Print a message indicating the start of training.</li>\n",
    "          <li>Call the <code>fit()</code> method of <code>stacked_classifier</code> to train the Stacked Classifier using the training data (<code>X_train_tvec</code>, <code>Y_train</code>).</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>\n",
    "        <strong>Prediction:</strong>\n",
    "        <ul>\n",
    "          <li>Print a message indicating the start of the prediction process.</li>\n",
    "          <li>Use the trained <code>stacked_classifier</code> to predict the labels for the testing data (<code>X_test_cleaned</code>) by calling the <code>predict()</code> method.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>\n",
    "        <strong>Evaluation - Classification Report:</strong>\n",
    "        <ul>\n",
    "          <li>Generate a classification report using the <code>classification_report()</code> function from <code>sklearn.metrics</code>.</li>\n",
    "          <li>The classification report includes metrics such as precision, recall, F1-score, and support for each class.</li>\n",
    "          <li>The classification report is printed and displayed as a DataFrame for easy readability.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>\n",
    "        <strong>Evaluation - Confusion Matrix:</strong>\n",
    "        <ul>\n",
    "          <li>Create a confusion matrix using the <code>confusion_matrix()</code> function from <code>sklearn.metrics</code>.</li>\n",
    "          <li>The confusion matrix is displayed as a heatmap using seaborn's <code>heatmap()</code> function to visualize the performance of the Stacked Classifier.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "    </ul>\n",
    "  </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97098b78",
   "metadata": {},
   "source": [
    "<h2>Boosting</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5fb5bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing AdaBoost Classifier with Multiple Weak Learners...\n",
      "AdaBoost Classifier Initialized with Multiple Weak Learners.\n",
      "Training AdaBoost Classifier...\n",
      "AdaBoost Classifier Training Complete.\n",
      "Making Predictions with AdaBoost Classifier...\n",
      "Prediction Complete with AdaBoost Classifier.\n",
      "              precision  recall  f1-score  support\n",
      "negative           0.87    0.70      0.78   686.00\n",
      "neutral            0.79    0.98      0.88  1198.00\n",
      "positive           0.94    0.82      0.88  1116.00\n",
      "accuracy           0.86    0.86      0.86     0.86\n",
      "macro avg          0.87    0.83      0.84  3000.00\n",
      "weighted avg       0.87    0.86      0.85  3000.00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "print(\"Initializing AdaBoost Classifier with Multiple Weak Learners...\")\n",
    "# Initialize multiple weak learners\n",
    "weak_learners = [\n",
    "    ('linear_svc', LinearSVC()),\n",
    "    ('kneighbors', KNeighborsClassifier()),\n",
    "    ('mlp', MLPClassifier(max_iter=100)),\n",
    "    ('gradient_boosting', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "# Initialize AdaBoostClassifier with multiple weak learners\n",
    "ada_classifier = AdaBoostClassifier(base_estimator=None, n_estimators=100, \n",
    "                                    learning_rate=1.0, algorithm='SAMME.R', \n",
    "                                    random_state=None)\n",
    "\n",
    "time.sleep(1)  # Simulating initialization time\n",
    "print(\"AdaBoost Classifier Initialized with Multiple Weak Learners.\")\n",
    "\n",
    "# Train the AdaBoost classifier\n",
    "print(\"Training AdaBoost Classifier...\")\n",
    "ada_classifier.fit(X_train_tvec, Y_train)\n",
    "print(\"AdaBoost Classifier Training Complete.\")\n",
    "\n",
    "# Predict using testing data\n",
    "print(\"Making Predictions with AdaBoost Classifier...\")\n",
    "ada_predictions = ada_classifier.predict(tvec.transform(X_test_cleaned))\n",
    "print(\"Prediction Complete with AdaBoost Classifier.\")\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(Y_test, ada_predictions, output_dict=True)\n",
    "data_report = pd.DataFrame(report).transpose().round(2)\n",
    "print(data_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e66d6b",
   "metadata": {},
   "source": [
    "<ul>\n",
    "  <li>\n",
    "    <strong>Initialization of AdaBoost Classifier with Multiple Weak Learners:</strong>\n",
    "    <ul>\n",
    "      <li>\n",
    "        <strong>Initialization of Weak Learners:</strong>\n",
    "        <ul>\n",
    "          <li>Import necessary modules for AdaBoostClassifier and weak learners: LinearSVC, KNeighborsClassifier, MLPClassifier, and GradientBoostingClassifier.</li>\n",
    "          <li>Define a list called <code>weak_learners</code> containing tuples of the form <code>(name, model)</code>, where <code>name</code> is a string identifier for the weak learner, and <code>model</code> is an instance of the corresponding classifier.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>\n",
    "        <strong>Initialization of AdaBoost Classifier:</strong>\n",
    "        <ul>\n",
    "          <li>Initialize an AdaBoostClassifier object named <code>ada_classifier</code>.</li>\n",
    "          <li>Specify parameters such as <code>base_estimator</code>, <code>n_estimators</code>, <code>learning_rate</code>, <code>algorithm</code>, and <code>random_state</code>.</li>\n",
    "          <li><code>base_estimator=None</code> indicates that AdaBoost will use a decision stump as the default weak learner.</li>\n",
    "          <li><code>n_estimators=100</code> specifies the number of weak learners (decision stumps) to be used in the ensemble.</li>\n",
    "          <li><code>learning_rate=1.0</code> controls the contribution of each weak learner to the final prediction.</li>\n",
    "          <li><code>algorithm='SAMME.R'</code> specifies the algorithm to use for boosting.</li>\n",
    "          <li><code>random_state=None</code> indicates that the random number generator is initialized based on the system's random number generator.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>\n",
    "        <strong>Simulated Initialization Time:</strong>\n",
    "        <ul>\n",
    "          <li>Use <code>time.sleep(1)</code> to simulate initialization time, delaying the program's execution by 1 second.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>\n",
    "        <strong>Training AdaBoost Classifier:</strong>\n",
    "        <ul>\n",
    "          <li>Print a message indicating the start of training.</li>\n",
    "          <li>Call the <code>fit()</code> method of <code>ada_classifier</code> to train the AdaBoostClassifier using the training data (<code>X_train_tvec</code>, <code>Y_train</code>).</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>\n",
    "        <strong>Prediction:</strong>\n",
    "        <ul>\n",
    "          <li>Print a message indicating the start of the prediction process.</li>\n",
    "          <li>Use the trained <code>ada_classifier</code> to predict the labels for the testing data (<code>X_test_cleaned</code>) by calling the <code>predict()</code> method.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>\n",
    "        <strong>Evaluation - Classification Report:</strong>\n",
    "        <ul>\n",
    "          <li>Generate a classification report using the <code>classification_report()</code> function from <code>sklearn.metrics</code>.</li>\n",
    "          <li>The classification report includes metrics such as precision, recall, F1-score, and support for each class.</li>\n",
    "          <li>The classification report is printed and displayed as a DataFrame for easy readability.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "      <li>\n",
    "        <strong>Evaluation - Confusion Matrix:</strong>\n",
    "        <ul>\n",
    "          <li>Create a confusion matrix using the <code>confusion_matrix()</code> function from <code>sklearn.metrics</code>.</li>\n",
    "          <li>The confusion matrix is displayed as a heatmap using seaborn's <code>heatmap()</code> function to visualize the performance of the AdaBoost Classifier.</li>\n",
    "        </ul>\n",
    "      </li>\n",
    "    </ul>\n",
    "  </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e735247",
   "metadata": {},
   "source": [
    "<h1>Bagging</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d2ccfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Bagging Classifier with Fewer Base Estimators...\n",
      "Bagging Classifier Initialized with Fewer Base Estimators.\n",
      "Training Bagging Classifier...\n",
      "Bagging Classifier Training Complete.\n",
      "Making Predictions with Bagging Classifier...\n",
      "Prediction Complete with Bagging Classifier.\n",
      "              precision  recall  f1-score  support\n",
      "negative           0.85    0.71      0.78   686.00\n",
      "neutral            0.82    0.97      0.89  1198.00\n",
      "positive           0.91    0.83      0.87  1116.00\n",
      "accuracy           0.86    0.86      0.86     0.86\n",
      "macro avg          0.86    0.84      0.85  3000.00\n",
      "weighted avg       0.86    0.86      0.86  3000.00\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize base classifiers with default parameters\n",
    "base_classifiers = [\n",
    "    ('linear_svc', LinearSVC()),\n",
    "    ('kneighbors', KNeighborsClassifier()),\n",
    "    ('mlp', MLPClassifier(max_iter=100)),\n",
    "    ('gradient_boosting', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "# Initialize BaggingClassifier with fewer base estimators\n",
    "bagging_classifier = BaggingClassifier(estimator=None, n_estimators=5, \n",
    "                                       max_samples=1.0, max_features=1.0, \n",
    "                                       bootstrap=True, bootstrap_features=False, \n",
    "                                       oob_score=False, warm_start=False, \n",
    "                                       n_jobs=None, random_state=None, verbose=0)\n",
    "\n",
    "print(\"Initializing Bagging Classifier with Fewer Base Estimators...\")\n",
    "time.sleep(1)  # Simulating initialization time\n",
    "print(\"Bagging Classifier Initialized with Fewer Base Estimators.\")\n",
    "\n",
    "# Train the Bagging classifier\n",
    "print(\"Training Bagging Classifier...\")\n",
    "bagging_classifier.fit(X_train_tvec, Y_train)\n",
    "print(\"Bagging Classifier Training Complete.\")\n",
    "\n",
    "# Predict using testing data\n",
    "print(\"Making Predictions with Bagging Classifier...\")\n",
    "bagging_predictions = bagging_classifier.predict(tvec.transform(X_test_cleaned))\n",
    "print(\"Prediction Complete with Bagging Classifier.\")\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(Y_test, bagging_predictions, output_dict=True)\n",
    "data_report = pd.DataFrame(report).transpose().round(2)\n",
    "print(data_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873f4885",
   "metadata": {},
   "source": [
    "<ul>\n",
    "  <li>\n",
    "    <strong>Bagging (Bootstrap Aggregating)</strong>:\n",
    "    <ul>\n",
    "      <li>Bagging is an ensemble learning technique.</li>\n",
    "      <li>It aims to improve the stability and accuracy of machine learning algorithms.</li>\n",
    "      <li>Bagging works by training multiple instances of a base learner on different subsets of the training data.</li>\n",
    "      <li>Each model's prediction is then averaged or combined in some way to make the final prediction.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Weak Learners:</strong>\n",
    "    <ul>\n",
    "      <li>In bagging, weak learners refer to the base models trained on subsets of the data.</li>\n",
    "      <li>These weak learners are typically simple models, such as decision trees.</li>\n",
    "      <li>Using multiple weak learners helps reduce overfitting and variance in the final prediction.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Initialization:</strong>\n",
    "    <ul>\n",
    "      <li>Initialize the Bagging Classifier with the chosen weak learners.</li>\n",
    "      <li>Each weak learner can be a different machine learning algorithm or a variant with different hyperparameters.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Training:</strong>\n",
    "    <ul>\n",
    "      <li>Train the Bagging Classifier on the training data.</li>\n",
    "      <li>Each weak learner is trained on a subset of the data, with replacement (bootstrap sampling).</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Prediction:</strong>\n",
    "    <ul>\n",
    "      <li>Make predictions using the trained Bagging Classifier on the testing data.</li>\n",
    "      <li>Combine the predictions of all weak learners, typically by averaging or voting, to make the final prediction.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  <li>\n",
    "    <strong>Evaluation:</strong>\n",
    "    <ul>\n",
    "      <li>Evaluate the performance of the Bagging Classifier using metrics such as accuracy, precision, recall, and F1-score.</li>\n",
    "      <li>Visualize the results using tools like confusion matrices or classification reports.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc154b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle stack\n",
    "\n",
    "import pickle\n",
    "\n",
    "#dump on picle\n",
    "pickle.dump(lr, open('../Model/stack_election.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
